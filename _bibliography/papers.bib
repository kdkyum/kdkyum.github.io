---
---

@inproceedings{kim2022nmdar,
  abbr={NeurIPS-W},
	author = {Kim, Dong-Kyum and Kwon, Jea and Cha, Meeyoung and C. Justin Lee},
	title = {Transformer needs NMDA receptor nonlinearity for long-term memory},
	year = {2022},
	abstract = {The NMDA receptor (NMDAR) in the hippocampus is essential for learning and memory. We find an interesting resemblance between deep models' nonlinear activation function and the NMDAR's nonlinear dynamics. In light of a recent study that compared the transformer architecture to the formation of hippocampal memory, this paper presents new findings that NMDAR-like nonlinearity may be essential for consolidating short-term working memory into long-term reference memory. We design a navigation task assessing these two memory functions and show that manipulating the activation function (i.e., mimicking the Mg$^{2+}$-gating of NMDAR) disrupts long-term memory formation. Our experimental data suggest that the concept of place cells and reference memory may reside in the feed-forward network and that nonlinearity plays a key role in these processes. Our findings propose that the transformer architecture and hippocampal spatial representation resemble by sharing the overlapping concept of NMDAR nonlinearity.},
  booktitle={NeurIPS 2022 Memory in Artificial and Real Intelligence workshop},
  url={https://openreview.net/forum?id=BJtzDKdXDW},
  youtube={https://www.youtube.com/watch?v=PQA_HuXTfes},
  pdf={NeurIPS22_MemARI.pdf},
}

@article{Kim2021.10.27.466049,
  abbr={Preprint},
	author = {Kim, Gwangsu and Kim, Dong-Kyum and Jeong, Hawoong},
	title = {Spontaneous emergence of music detectors in a deep neural network},
	elocation-id = {2021.10.27.466049},
	year = {2021},
	doi = {10.1101/2021.10.27.466049},
	publisher = {Cold Spring Harbor Laboratory},
  code = {https://github.com/kgspiano/Music},
	abstract = {Music exists in almost every society, has universal acoustic features, and is processed by distinct neural circuits in humans even with no experience of musical training. These characteristics suggest an innateness of the sense of music in our brain, but it is unclear how this innateness emerges and what functions it has. Here, using an artificial deep neural network that models the auditory information processing of the brain, we show that units tuned to music can spontaneously emerge by learning natural sound detection, even without learning music. By simulating the responses of network units to 35,487 natural sounds in 527 categories, we found that various subclasses of music are strongly clustered in the embedding space, and that this clustering arises from the music-selective response of the network units. The music-selective units encoded the temporal structure of music in multiple timescales, following the population-level response characteristics observed in the brain. We confirmed that the process of generalization is critical for the emergence of music-selectivity and that music-selectivity can work as a functional basis for the generalization of natural sound, thereby elucidating its origin. These findings suggest that our sense of music can be innate, universally shaped by evolutionary adaptation to process natural sound.One-sentence summary Music-selectivity can arise spontaneously in deep neural networks trained for natural sound detection without learning music.Competing Interest StatementThe authors have declared no competing interest.},
	html = {https://www.biorxiv.org/content/early/2021/11/09/2021.10.27.466049},
	eprint = {https://www.biorxiv.org/content/early/2021/11/09/2021.10.27.466049.full.pdf},
  bibtex_show={true},
	journal = {bioRxiv}
}

@article{lee2022meb,
  abbr={Preprint},
  html = {https://arxiv.org/abs/2207.05961},
  author = {Lee, Sangyun and Kim, Dong-Kyum and Park, Jong-Min and Kim, Won Kyu and Park, Hyunggyu and Lee, Jae Sung},
  title = {Multidimensional entropic bound: Estimator of entropy production for general Langevin dynamics with an arbitrary time-dependent protocol},
  journal = {arXiv},
  year = {2022},
  bibtex_show={true},
  abstract={Entropy production (EP) is a key quantity in thermodynamics, and yet measuring EP has remained a challenging task. Here we introduce an EP estimator, called multidimensional entropic bound (MEB), utilizing an ensemble of trajectories without knowing the details of a given system. MEB is a unified method in the sense that it is applicable to both overdamped and underdamped Langevin dynamics, irrespective of the time dependence of the driving protocol. In addition, MEB is computationally efficient because optimization is unnecessary. We apply our developed estimator to three physical systems driven by time-dependent protocols pertaining to experiments using optical tweezers: a dragged Brownian particle, a pulling process of a harmonic chain, and an unfolding process of an RNA hairpin. Numerical simulations confirm the validity and efficiency of our method.}
}

@article{PhysRevResearch.4.023051,
  abbr = {PRR},
  title = {Estimating entropy production with odd-parity state variables via machine learning},
  author = {Kim, Dong-Kyum and Lee, Sangyun and Jeong, Hawoong},
  journal = {Phys. Rev. Research},
  volume = {4},
  issue = {2},
  pages = {023051},
  numpages = {7},
  year = {2022},
  month = {Apr},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevResearch.4.023051},
  code = {https://github.com/kdkyum/RatchetDRL},
  html = {https://link.aps.org/doi/10.1103/PhysRevResearch.4.023051},
  bibtex_show={true},
  abstract={Entropy production (EP) is a central measure in nonequilibrium thermodynamics, as it can quantify the irreversibility of a process as well as its energy dissipation in special cases. Using the time-reversal asymmetry in a system's path probability distribution, many methods have been developed to estimate EP from only trajectory data. However, for systems with odd-parity variables that prevail in nonequilibrium systems, EP estimation via machine learning has not been covered. In this study, we develop a machine-learning method for estimating the EP in a stochastic system with odd-parity variables through multiple neural networks, which enables us to measure EP with only trajectory data and parity information. We demonstrate our method with two systems, an underdamped bead-spring model and a one-particle odd-parity Markov jump process.},
}

@article{PhysRevResearch.4.033094,
  abbr = {PRR},
  title = {Inferring dissipation maps from videos using convolutional neural networks},
  author = {Bae, Youngkyoung and Kim, Dong-Kyum and Jeong, Hawoong},
  journal = {Phys. Rev. Research},
  volume = {4},
  issue = {3},
  pages = {033094},
  numpages = {9},
  year = {2022},
  month = {Aug},
  publisher = {American Physical Society},
  code = {https://github.com/qodudrud/CNEEP},
  doi = {10.1103/PhysRevResearch.4.033094},
  html = {https://link.aps.org/doi/10.1103/PhysRevResearch.4.033094},
  abstract={In the study of living organisms at mesoscopic scales, attaining a measure of dissipation or entropy production (EP) is essential to gain an understanding of their nonequilibrium dynamics. However, when tracking the relevant variables is impractical, it is challenging to figure out where and to what extent dissipation occurs from recorded time-series images from experiments. In this paper we develop an estimator that can, without detailed knowledge of the given systems, quantify the stochastic EP and produce a spatiotemporal pattern of the EP (or dissipation map) from videos through an unsupervised learning algorithm. Applying a convolutional neural network (CNN), our estimator allows us to visualize where the dissipation occurs as well as its time evolution in a video by looking at an attention map of the CNN's last layer. We demonstrate that our estimator accurately measures the stochastic EP and provides a locally heterogeneous dissipation map, which is mainly concentrated in the origins of a nonequilibrium state, from generated Brownian videos of various models. We further confirm high performance even with noisy, low-spatial-resolution data and partially observed situations. Our method will provide a practical way to obtain dissipation maps and ultimately contribute to uncovering the source and the dissipation mechanisms of complex nonequilibrium phenomena.},
  bibtex_show={true},
}

@article{PhysRevResearch.3.L022002,
  abbr = {PRR},
  title = {Deep reinforcement learning for feedback control in a collective flashing ratchet},
  author = {Kim, Dong-Kyum and Jeong, Hawoong},
  journal = {Phys. Rev. Research},
  volume = {3},
  issue = {2},
  pages = {L022002},
  numpages = {6},
  year = {2021},
  month = {Apr},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevResearch.3.L022002},
  code = {https://github.com/kdkyum/RatchetDRL},
  html = {https://link.aps.org/doi/10.1103/PhysRevResearch.3.L022002},
  abstract={A collective flashing ratchet transports Brownian particles using a spatially periodic, asymmetric, and time-dependent on-off switchable potential. The net current of the particles in this system can be substantially increased by feedback control based on the particle positions. Several feedback policies for maximizing the current have been proposed, but optimal policies have not been found for a moderate number of particles. Here, we use deep reinforcement learning (RL) to find optimal policies, with results showing that policies built with a suitable neural network architecture outperform the previous policies. Moreover, even in a time-delayed feedback situation where the on-off switching of the potential is delayed, we demonstrate that the policies provided by deep RL provide higher currents than the previous strategies.},
  selected={true},
  bibtex_show={true},
}


@article{kim2020neep,
  abbr = {PRL},
  title = {Learning Entropy Production via Neural Networks},
  author = {Kim, Dong-Kyum and Bae, Youngkyoung and Lee, Sangyun and Jeong, Hawoong},
  journal = {Phys. Rev. Lett.},
  volume = {125},
  issue = {14},
  pages = {140604},
  numpages = {6},
  year = {2020},
  month = {Oct},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevLett.125.140604},
  html = {https://link.aps.org/doi/10.1103/PhysRevLett.125.140604},
  arxiv = {2003.04166},
  code = {https://github.com/kdkyum/neep},
  abstract = {This Letter presents a neural estimator for entropy production (NEEP), that estimates entropy production (EP) from trajectories of relevant variables without detailed information on the system dynamics. For steady state, we rigorously prove that the estimator, which can be built up from different choices of deep neural networks, provides stochastic EP by optimizing the objective function proposed here. We verify the NEEP with the stochastic processes of the bead spring and discrete flashing ratchet models and also demonstrate that our method is applicable to high-dimensional data and can provide coarse-grained EP for Markov systems with unobservable states.},
  selected={true},
  bibtex_show={true},
}

@article{kim2020multi,
  abbr = {JKPS},
  bibtex_show={true},
  title={Multi-label classification of historical documents by using hierarchical attention networks},
  author={Kim, Dong-Kyum and Lee, Byunghwee and Kim, Daniel and Jeong, Hawoong},
  journal={Journal of the Korean Physical Society},
  volume={76},
  number={5},
  pages={368--377},
  year={2020},
  publisher={Springer},
  html = {https://link.springer.com/article/10.3938/jkps.76.368},
  abstract={The quantitative analysis of digitized historical documents has begun in earnest in recent years. Text classification is of particular importance for quantitative historical analysis because it helps to search literature efficiently and to determine the important subjects of a particular age. While numerous historians have joined together to classify large-scale historical documents, consistent classification among individual researchers has not been achieved. In this study, we present a classification method for large-scale historical data that uses a recently developed supervised learning algorithm called the Hierarchical Attention Network (HAN). By applying various classification methods to the Annals of the Joseon Dynasty (AJD), we show that HAN is more accurate than conventional techniques with word-frequency-based features. HAN provides the extent that a particular sentence or word contributes to the classification process through a quantitative value called ’attention’. We extract the representative keywords from various categories by using the attention mechanism and show the evolution of the keywords over the 472-year span of the AJD. Our results reveal that largely two groups of event categories are found in the AJD. In one group, the representative keywords of the categories were stable over long periods while the keywords in the other group varied rapidly, exhibiting repeatedly changing characteristics of the categories. Observing such macroscopic changes of representative words may provide insight into how a particular topic changes over a historical period.}
}